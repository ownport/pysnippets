#!/usr/bin/env python
#   -*- coding: utf-8 -*-
#   
#   XPath selector
#
#   based on Scrapy selectors https://github.com/scrapy/scrapy/tree/master/scrapy/selector
#

import re
from lxml import etree

def flatten(x):
    """flatten(sequence) -> list

    Returns a single, flat list which contains all elements retrieved
    from the sequence and all recursively contained sub-sequences
    (iterables).

    Examples:
    >>> [1, 2, [3,4], (5,6)]
    [1, 2, [3, 4], (5, 6)]
    >>> flatten([[[1,2,3], (42,None)], [4,5], [6], 7, (8,9,10)])
    [1, 2, 3, 42, None, 4, 5, 6, 7, 8, 9, 10]"""

    result = []
    for el in x:
        if hasattr(el, "__iter__"):
            result.extend(flatten(el))
        else:
            result.append(el)
    return result

def extract_regex(regex, text, encoding='utf-8'):
    """Extract a list of unicode strings from the given text/encoding using the following policies:

    * if the regex contains a named group called "extract" that will be returned
    * if the regex contains multiple numbered groups, all those will be returned (flattened)
    * if the regex doesn't contain any group the entire regex matching is returned
    """

    if isinstance(regex, basestring):
        regex = re.compile(regex, re.UNICODE)

    try:
        strings = [regex.search(text).group('extract')]   # named group
    except:
        strings = regex.findall(text)    # full regex or numbered groups
    strings = flatten(strings)
    return strings

class XPathSelectorList(list):

    def __getslice__(self, i, j):
        return self.__class__(list.__getslice__(self, i, j))

    def select(self, xpath):
        return self.__class__(flatten([x.select(xpath) for x in self]))

    def re(self, regex):
        return flatten([x.re(regex) for x in self])

    def extract(self):
        return [x.extract() for x in self]

    def extract_unquoted(self):
        return [x.extract_unquoted() for x in self]

class XPathSelector(object):
    
    def __init__(self, html_content=None, base_url='', _root=None, _expr=None, namespaces=None):
        ''' init
        '''
        self.namespaces = namespaces
        parser = self._parser(recover=True, encoding='utf-8')
        if html_content is not None:
            _root = etree.fromstring(html_content, parser=parser, base_url=base_url)
        self._root = _root
        self._expr = _expr

    def select(self, xpath):
        '''returns a list of new selectors.
        '''
        try:
            xpathev = self._root.xpath
        except AttributeError:
            return XPathSelectorList([])

        try:
            result = xpathev(xpath, namespaces=self.namespaces)
        except etree.XPathError:
            raise ValueError("Invalid XPath: %s" % xpath)

        if type(result) is not list:
            result = [result]

        result = [self.__class__(_root=x, _expr=xpath, namespaces=self.namespaces)
                  for x in result]
        return XPathSelectorList(result)

    def re(self, regex):
        return extract_regex(regex, self.extract())
        
    def extract(self):
        try:
            return etree.tostring(self._root, method=self._tostring_method, encoding=unicode, with_tail=False)
        except (AttributeError, TypeError):
            if self._root is True:
                return u'1'
            elif self._root is False:
                return u'0'
            else:
                return unicode(self._root)

    def register_namespace(self, prefix, uri):
        if self.namespaces is None:
            self.namespaces = {}
        self.namespaces[prefix] = uri

    def __str__(self):
        data = repr(self.extract()[:40])
        return "<%s xpath=%r data=%s>" % (type(self).__name__, self._expr, data)

    __repr__ = __str__

class XmlXPathSelector(XPathSelector):
    __slots__ = ()
    _parser = etree.XMLParser
    _tostring_method = 'xml'

class HtmlXPathSelector(XPathSelector):
    __slots__ = ()
    _parser = etree.HTMLParser
    _tostring_method = 'html'


if __name__ == '__main__':
    html_content = '''
    <html>
     <head>
      <base href='http://example.com/' />
      <title>Example website</title>
     </head>
     <body>
      <div id='images'>
       <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' /></a>
       <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' /></a>
       <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' /></a>
       <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' /></a>
       <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' /></a>
      </div>
     </body>
    </html>
    '''
    hxs = HtmlXPathSelector(html_content) 
    assert hxs.select('//title/text()').extract() == [u'Example website']
    assert hxs.select('//base/@href').extract() == [u'http://example.com/']
    assert hxs.select('//div/@id').extract() == [u'images']
    assert hxs.select('//a[@href="image2.html"]/img/@src').extract() == [u'image2_thumb.jpg']
    result = [u'image1_thumb.jpg', u'image2_thumb.jpg', u'image3_thumb.jpg', u'image4_thumb.jpg', u'image5_thumb.jpg']
    assert hxs.select('//a').select('img/@src').extract() == result


